{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4aef348",
   "metadata": {},
   "source": [
    "## Portfolio Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619c315",
   "metadata": {},
   "source": [
    "In this Portfolio task, you will continue working with the dataset you have used in portfolio 2. But the difference is that the rating column has been changed with like or dislike values. Your task is to train classification models to predict whether a user like or dislike an item.  \n",
    "\n",
    "\n",
    "The header of the csv file is shown below. \n",
    "\n",
    "| userId | timestamp | review | item| rating | helpfulness | gender | category |\n",
    "    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | \n",
    "    \n",
    "#### Description of Fields\n",
    "\n",
    "* __userId__ - the user's id\n",
    "* __timestamp__ - the timestamp indicating when the user rated the shopping item\n",
    "* __review__ - the user's review comments of the item\n",
    "* __item__ - the name of the item\n",
    "* __rating__ - the user like or dislike the item\n",
    "* __helpfulness__ - average rating from other users on whether the review comment is helpful. 6-helpful, 0-not helpful. \n",
    "* __gender__ - the gender of the user, F- female, M-male\n",
    "* __category__ - the category of the shopping item\n",
    "\n",
    "\n",
    "Your high level goal in this notebook is to try to build and evaluate predictive models for 'rating' from other available features - predict the value of the __rating__ field in the data from some of the other fields. More specifically, you need to complete the following major steps: \n",
    "1) Explore the data. Clean the data if necessary. For example, remove abnormal instanaces and replace missing values.\n",
    "2) Convert object features into digit features by using an encoder\n",
    "3) Study the correlation between these features. \n",
    "4) Split the dataset and train a logistic regression model to predict 'rating' based on other features. Evaluate the accuracy of your model.\n",
    "5) Split the dataset and train a KNN model to predict 'rating' based on other features. You can set K with an ad-hoc manner in this step. Evaluate the accuracy of your model.\n",
    "6) Tune the hyper-parameter K in KNN to see how it influences the prediction performance\n",
    "\n",
    "Note 1: We did not provide any description of each step in the notebook. You should learn how to properly comment your notebook by yourself to make your notebook file readable. \n",
    "\n",
    "Note 2: you are not being evaluated on the ___accuracy___ of the model but on the ___process___ that you use to generate it. Please use both ___Logistic Regression model___ and ___KNN model___ for solving this classification problem. Accordingly, discuss the performance of these two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47be0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c57251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4259</td>\n",
       "      <td>11900</td>\n",
       "      <td>Finally, Something for (Relatively) Nothing</td>\n",
       "      <td>MyPoints.com</td>\n",
       "      <td>like</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Online Stores &amp; Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4259</td>\n",
       "      <td>12000</td>\n",
       "      <td>Shocking!</td>\n",
       "      <td>Sixth Sense</td>\n",
       "      <td>like</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4259</td>\n",
       "      <td>12000</td>\n",
       "      <td>Simply Shaggadelic!</td>\n",
       "      <td>Austin Powers: The Spy Who Shagged Me</td>\n",
       "      <td>like</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4259</td>\n",
       "      <td>12000</td>\n",
       "      <td>Better Than The First!</td>\n",
       "      <td>Toy Story 2</td>\n",
       "      <td>like</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>Movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4259</td>\n",
       "      <td>12000</td>\n",
       "      <td>Blair Witch made me appreciate this</td>\n",
       "      <td>Star Wars Episode I: The Phantom Menace</td>\n",
       "      <td>dislike</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Movies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  timestamp                                       review  \\\n",
       "0    4259      11900  Finally, Something for (Relatively) Nothing   \n",
       "1    4259      12000                                    Shocking!   \n",
       "2    4259      12000                          Simply Shaggadelic!   \n",
       "3    4259      12000                       Better Than The First!   \n",
       "4    4259      12000          Blair Witch made me appreciate this   \n",
       "\n",
       "                                      item   rating  helpfulness gender  \\\n",
       "0                             MyPoints.com     like            4      F   \n",
       "1                              Sixth Sense     like            4      F   \n",
       "2    Austin Powers: The Spy Who Shagged Me     like            4      F   \n",
       "3                              Toy Story 2     like            3      F   \n",
       "4  Star Wars Episode I: The Phantom Menace  dislike            4      F   \n",
       "\n",
       "                   category  \n",
       "0  Online Stores & Services  \n",
       "1                    Movies  \n",
       "2                    Movies  \n",
       "3                    Movies  \n",
       "4                    Movies  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "df = pd.read_csv('Portfolio 3.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e848851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2899, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # size before cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b56c78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId         0\n",
       "timestamp      0\n",
       "review         0\n",
       "item           0\n",
       "rating         0\n",
       "helpfulness    0\n",
       "gender         0\n",
       "category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Explore the data. Clean the data if necessary. For example, remove abnormal instanaces and replace missing values.\n",
    "\n",
    "df.isna().sum() # checking if there is any null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca6de5",
   "metadata": {},
   "source": [
    "Hence there are no null values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9f1812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Online Stores & Services', 'Movies', 'Hotels & Travel', 'Games',\n",
       "       'Personal Finance', 'Media', 'Kids & Family',\n",
       "       'Restaurants & Gourmet', 'Books'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique() # cross-verify if there are any abnormal data in the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044ec2a",
   "metadata": {},
   "source": [
    "Checked with the above code for all other required columns i.e. with review, item, rating, helpfulness, gender; no abnormal value/wrong values are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe630f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2899 entries, 0 to 2898\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   userId       2899 non-null   int64 \n",
      " 1   timestamp    2899 non-null   int64 \n",
      " 2   review       2899 non-null   object\n",
      " 3   item         2899 non-null   object\n",
      " 4   rating       2899 non-null   object\n",
      " 5   helpfulness  2899 non-null   int64 \n",
      " 6   gender       2899 non-null   object\n",
      " 7   category     2899 non-null   object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 181.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2) Convert object features into digit features by using an encoder \n",
    "\n",
    "df.info() # check type of data, we found 5 object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082586f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder() # initiating OrdinalEncoder() object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3446f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning it to main dataset\n",
    "df['review'] = enc.fit_transform(df[['review']])\n",
    "df['item'] = enc.fit_transform(df[['item']])\n",
    "df['rating'] = enc.fit_transform(df[['rating']])\n",
    "df['gender'] = enc.fit_transform(df[['gender']])\n",
    "df['category'] = enc.fit_transform(df[['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320d26d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2899 entries, 0 to 2898\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   userId       2899 non-null   int64  \n",
      " 1   timestamp    2899 non-null   int64  \n",
      " 2   review       2899 non-null   float64\n",
      " 3   item         2899 non-null   float64\n",
      " 4   rating       2899 non-null   float64\n",
      " 5   helpfulness  2899 non-null   int64  \n",
      " 6   gender       2899 non-null   float64\n",
      " 7   category     2899 non-null   float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 181.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # check converted types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773632f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlations value:\n",
      "\n",
      "review and rating:  -0.046934643586446896\n",
      "item and rating:  0.013628997625434916\n",
      "gender and rating:  0.022575696214408688\n",
      "category and rating:  -0.11631209500485062\n"
     ]
    }
   ],
   "source": [
    "# 3) Study the correlation between these features.\n",
    "\n",
    "# correlation between columns and rating\n",
    "df_review = df['rating'].corr(df['review'])\n",
    "df_item = df['rating'].corr(df['item'])\n",
    "df_gender = df['rating'].corr(df['gender'])\n",
    "df_category = df['rating'].corr(df['category'])\n",
    "\n",
    "print(\"The correlations value:\\n\")\n",
    "print(\"review and rating: \", df_review)\n",
    "print(\"item and rating: \",df_item)\n",
    "print(\"gender and rating: \",df_gender)\n",
    "print(\"category and rating: \",df_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d0da8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2319, 8)\n",
      "(580, 8)\n"
     ]
    }
   ],
   "source": [
    "# 4) Split the dataset and train a logistic regression model to predict 'rating' based on other features. Evaluate the accuracy of your model. \n",
    "\n",
    "train_case, test_case = train_test_split(df, test_size=0.2, random_state=142) # Splitting data into 80% training and 20% testing data\n",
    "print(train_case.shape)\n",
    "print(test_case.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15daf887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train size: (2319, 4)\n",
      "y train size: (2319,)\n",
      "x test size: (580, 4)\n",
      "y test size: (580,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_case[['review', 'item', 'gender', 'category']] # select these four features that directly can affect the ratings.\n",
    "y_train = train_case['rating'] # take rating in y-axis to evaluate the like and dislike of the user\n",
    "x_test = test_case.drop(['userId', 'timestamp','rating','helpfulness'], axis = 1) # drop unwanted columns that are not directly relate to rating values.\n",
    "y_test = test_case['rating'] # same in training data and testing data\n",
    "\n",
    "print(\"x train size:\", x_train.shape)\n",
    "print(\"y train size:\", y_train.shape)\n",
    "print(\"x test size:\", x_test.shape)\n",
    "print(\"y test size:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9fb77fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting logistic regression model\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "968fee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict data of logistic regression\n",
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "470bd985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:\n",
      "\n",
      "train data:  0.6326002587322122\n",
      "test data:  0.6413793103448275\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score:\\n\")\n",
    "print(\"train data: \", accuracy_score(y_train,train_predict))\n",
    "print(\"test data: \", accuracy_score(y_test,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3beeb779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(), n_features_to_select=5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using RFE model\n",
    "rfe = linear_model.LogisticRegression()\n",
    "selector = RFE(rfe,n_features_to_select=5,step=1)\n",
    "selector.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b58864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict data of RFE model\n",
    "train_fpredict = selector.predict(x_train)\n",
    "test_fpredict = selector.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "233df2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:\n",
      "\n",
      "train data after RFE:  0.6326002587322122\n",
      "test data after RFE:  0.6413793103448275\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score:\\n\")\n",
    "print(\"train data after RFE: \", accuracy_score(y_train,train_fpredict))\n",
    "print(\"test data after RFE: \", accuracy_score(y_test,test_fpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b71ea2",
   "metadata": {},
   "source": [
    "The accuracy of test data is almost same while using RFE and without using RFE here, the difference of training and testing data accuracy score is around 0.01 concluding that the model is well predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3853466b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Split the dataset and train a KNN model to predict 'rating' based on other features. You can set K with an ad-hoc manner in this step\n",
    "# and evaluate the accuracy of your model.\n",
    "\n",
    "# using knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "291fe24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy is:  0.6172413793103448\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(x_test) # predicting data\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test) # counting accuracy score\n",
    "print('Testing accuracy is: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d055b88",
   "metadata": {},
   "source": [
    "Hence, the knn model will help in selecting K value and find the best scored accuracy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eb861a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value:  37\n",
      "The accuracy:  0.6373413942379459\n"
     ]
    }
   ],
   "source": [
    "# 6) Tune the hyper-parameter K in KNN to see how it influences the prediction performance\n",
    "\n",
    "parameter_grid = {'n_neighbors': range(1, 50)}\n",
    "knn_tunning = KNeighborsClassifier()\n",
    "clf = GridSearchCV(knn_tunning, parameter_grid, scoring='accuracy', cv=10)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Identify the best parameters\n",
    "print('Best K value: ', clf.best_params_['n_neighbors'])\n",
    "print('The accuracy: ', clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de79e7",
   "metadata": {},
   "source": [
    "Looking at the results of que 5 and 6, we can say that by tunning the hyper-parameter K, we can better select the k-value and thus influencing the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f64bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
